{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pacakges\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting directory\n",
    "EPOCHS = 25\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "default_image_size = tuple((256, 256))\n",
    "image_size = 0\n",
    "directory_root = r'C:\\Users\\BERLIN\\Desktop\\Image-Augmentation-using-GAN-master\\dataset'\n",
    "width=256\n",
    "height=256\n",
    "depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all image into numpy array (function)\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, default_image_size)   \n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing aflatoxin ...\n",
      "[INFO] Processing anthracnose ...\n",
      "[INFO] Processing Apricot monilia ...\n",
      "[INFO] Processing Black Root Rot ...\n",
      "[INFO] Processing Black Rot ...\n",
      "[INFO] Processing Botrytis ...\n",
      "[INFO] Processing carnesiyam ...\n",
      "[INFO] Processing downy mildew ...\n",
      "[INFO] Processing leaf rust ...\n",
      "[INFO] Processing mosaic virus ...\n",
      "[INFO] Processing Oedema ...\n",
      "[INFO] Processing Orange Rust ...\n",
      "[INFO] Processing Powdery Mildew ...\n",
      "[INFO] Processing Purple Blotch ...\n",
      "[INFO] Processing sooty blotch ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "# loading all images from folder and subfolder\n",
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir :\n",
    "        # remove .DS_Store from list\n",
    "        if directory == \".DS_Store\" :\n",
    "            root_dir.remove(directory)\n",
    "\n",
    "    for plant_folder in root_dir :\n",
    "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "        \n",
    "        for disease_folder in plant_disease_folder_list :\n",
    "            # remove .DS_Store from list\n",
    "            if disease_folder == \".DS_Store\" :\n",
    "                plant_disease_folder_list.remove(disease_folder)\n",
    "\n",
    "        for plant_disease_folder in plant_disease_folder_list:\n",
    "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
    "                \n",
    "            for single_plant_disease_image in plant_disease_image_list :\n",
    "                if single_plant_disease_image == \".DS_Store\" :\n",
    "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
    "\n",
    "            for image in plant_disease_image_list[:200]:\n",
    "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "                    image_list.append(convert_image_to_array(image_directory))\n",
    "                    label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the length of the list\n",
    "image_size = len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pickle for loading label file\n",
    "import pickle\n",
    "# binarizer for normallization\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apricot monilia' 'Black Root Rot' 'Black Rot' 'Botrytis' 'Oedema'\n",
      " 'Orange Rust' 'Powdery Mildew' 'Purple Blotch' 'aflatoxin' 'anthracnose'\n",
      " 'carnesiyam' 'downy mildew' 'leaf rust' 'mosaic virus' 'sooty blotch']\n"
     ]
    }
   ],
   "source": [
    "# checking all classes\n",
    "print(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spliting data to train, test\n"
     ]
    }
   ],
   "source": [
    "# spliting our dataset into train and test split\n",
    "print(\"[INFO] Spliting data to train, test\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data generator for validation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our squeezenet model\n",
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# distribution\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\berlin\\.conda\\envs\\opencv-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 108s 13s/step - loss: 0.9958 - accuracy: 0.1208 - val_loss: 0.6304 - val_accuracy: 0.1176\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 66s 11s/step - loss: 0.8482 - accuracy: 0.1433 - val_loss: 0.6386 - val_accuracy: 0.0588\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 79s 14s/step - loss: 0.8422 - accuracy: 0.2075 - val_loss: 0.7995 - val_accuracy: 0.0588\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 81s 13s/step - loss: 0.8175 - accuracy: 0.1761 - val_loss: 0.6803 - val_accuracy: 0.0588\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 82s 14s/step - loss: 0.7349 - accuracy: 0.1859 - val_loss: 0.7844 - val_accuracy: 0.0588\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 73s 12s/step - loss: 0.7529 - accuracy: 0.2419 - val_loss: 0.5900 - val_accuracy: 0.0784\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 71s 12s/step - loss: 0.6964 - accuracy: 0.2976 - val_loss: 0.4567 - val_accuracy: 0.0588\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 81s 15s/step - loss: 0.6816 - accuracy: 0.2485 - val_loss: 0.5594 - val_accuracy: 0.0784\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 68s 11s/step - loss: 0.6254 - accuracy: 0.3849 - val_loss: 0.5135 - val_accuracy: 0.1765\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.5782 - accuracy: 0.3243 - val_loss: 0.5431 - val_accuracy: 0.0784\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 70s 12s/step - loss: 0.5666 - accuracy: 0.3710 - val_loss: 0.6230 - val_accuracy: 0.0196\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 71s 12s/step - loss: 0.5101 - accuracy: 0.4303 - val_loss: 0.6366 - val_accuracy: 0.0196\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 72s 12s/step - loss: 0.4787 - accuracy: 0.2928 - val_loss: 0.6390 - val_accuracy: 0.0392\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 77s 13s/step - loss: 0.5103 - accuracy: 0.2661 - val_loss: 0.5198 - val_accuracy: 0.0588\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 75s 12s/step - loss: 0.4378 - accuracy: 0.3573 - val_loss: 0.3965 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 81s 13s/step - loss: 0.4205 - accuracy: 0.3404 - val_loss: 0.3990 - val_accuracy: 0.0588\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 77s 14s/step - loss: 0.3855 - accuracy: 0.3332 - val_loss: 0.4433 - val_accuracy: 0.0588\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 84s 14s/step - loss: 0.3590 - accuracy: 0.3172 - val_loss: 0.3921 - val_accuracy: 0.0588\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 90s 16s/step - loss: 0.3311 - accuracy: 0.3927 - val_loss: 0.3469 - val_accuracy: 0.0588\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 93s 15s/step - loss: 0.2862 - accuracy: 0.5367 - val_loss: 0.3125 - val_accuracy: 0.1373\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 92s 15s/step - loss: 0.2934 - accuracy: 0.4563 - val_loss: 0.3029 - val_accuracy: 0.1373\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 92s 17s/step - loss: 0.2661 - accuracy: 0.4475 - val_loss: 0.3318 - val_accuracy: 0.0392\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 111s 19s/step - loss: 0.2493 - accuracy: 0.4869 - val_loss: 0.3309 - val_accuracy: 0.0588\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 142s 23s/step - loss: 0.2354 - accuracy: 0.5455 - val_loss: 0.3136 - val_accuracy: 0.0392\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 143s 26s/step - loss: 0.2110 - accuracy: 0.5101 - val_loss: 0.3137 - val_accuracy: 0.0196\n"
     ]
    }
   ],
   "source": [
    "# training our model\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1\n",
    "    )\n",
    "\n",
    "## training steps was carry on for 25 iterations..i u need means just increase by changing epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 0.3137 - accuracy: 0.0196\n"
     ]
    }
   ],
   "source": [
    "# evaluating our model\n",
    "scores = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] Saving model...\")\n",
    "pickle.dump(model,open('cnn_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_output(x):\n",
    "    plt.imshow(array_to_img(x))\n",
    "    return label_binarizer.classes_[np.argmax(model.predict(np.expand_dims(x, axis = 0)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.imread(r'C:\\Users\\BERLIN\\Desktop\\Image-Augmentation-using-GAN-master\\dataset\\train\\aflatoxin\\4z.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our model\n",
    "model.save(\"model_squeeze.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading our model\n",
    "model = load_model('model_squeeze.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 85, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 85, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 42, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              57803776  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                15375     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 58,102,671\n",
      "Trainable params: 58,099,791\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from IPython.display import Image, display\n",
    "# from learntools.deep_learning.decode_predictions import decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement learntools\n",
      "ERROR: No matching distribution found for learntools\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling our model (categorical_crossentropy for multiclass, binary_crossentropy for 2 classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "# this is ur imput image need to classify \n",
    "img = r'C:\\Users\\BERLIN\\Desktop\\Image-Augmentation-using-GAN-master\\dataset\\train\\leaf rust\\download (1).jpg' # imput is as image\n",
    "img = np.full((100,80,3), 12, dtype = np.uint8)\n",
    "img = cv2.resize(img,(256,256))\n",
    "img = np.reshape(img,[1,256,256,3])\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "classes = model.predict_classes(img)\n",
    "\n",
    "print (classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leaf rust'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {0:'Apricot monilia',1:'carnesiyam',2:'aflatoxin',3:'alternaria',4:'anthracnose',5:'Black Root Rot',6:'Black Rot',7:'Botrytis',8:'downy mildew',9:'leaf rust',10:'mosaic virus',11:'Oedema',12:'Orange Rust',13:'Powdery Mildew',14:'Purple Blotch',15:'sooty blotch'}\n",
    "dict[classes.item()] # output as our class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correctly predicted\n",
    "#'leafrust 'isthe output of our model classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
